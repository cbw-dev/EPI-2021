[["index.html", "Epigenomic Analysis 2021 Workshop Info Pre-work Schedule", " Epigenomic Analysis 2021 Faculty: Guillaume Bourque, Martin Hirst, David Bujold, Jose Hector Galvez, Edmund Su, BF Francis Ouellette, Rachade Hmamouchi September 13, 2021 - September 15, 2021 Workshop Info Welcome to the 2021 Epigenomic Analysis Canadian Bioinformatics Workshop webpage! Pre-work You can find your pre-work here. Schedule :root { --schedule-primary-color: #4A6BFF; --schedule-border-color: #EAECEF; --schedule-text-color: #555; } .schedule-card { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif; border: 1px solid var(--schedule-border-color); border-radius: 12px; margin: 2em 0; box-shadow: 0 4px 12px rgba(0,0,0,0.05); overflow: hidden; } .schedule-tabs { display: flex; justify-content: space-between; align-items: center; border-bottom: 1px solid var(--schedule-border-color); background-color: #fff; } .schedule-tabs-wrapper { position: relative; flex-grow: 1; overflow: hidden; } .schedule-tabs-wrapper::before, .schedule-tabs-wrapper::after { content: ''; position: absolute; top: 0; bottom: 0; width: 50px; pointer-events: none; transition: opacity 0.2s; opacity: 0; } .schedule-tabs-wrapper::before { left: 0; background: linear-gradient(to left, rgba(255,255,255,0), #fff 70%); } .schedule-tabs-wrapper::after { right: 0; background: linear-gradient(to right, rgba(255,255,255,0), #fff 70%); } .schedule-tabs-wrapper.scrolled-left::before { opacity: 1; } .schedule-tabs-wrapper.scrolled-right::after { opacity: 1; } .schedule-tab-buttons { display: flex; overflow-x: auto; white-space: nowrap; -ms-overflow-style: none; scrollbar-width: none; scroll-behavior: smooth; } .schedule-tab-buttons::-webkit-scrollbar { display: none; } .timezone-selector-container { display: flex; align-items: center; gap: 0.75em; padding: 0 20px; } .timezone-selector-container label { font-size: 0.9em; color: var(--schedule-text-color); font-weight: 500; } .schedule-tabs select { padding: 6px 10px; border-radius: 6px; border: 1px solid #ccc; background-color: #fff; } .schedule-tab { padding: 14px 20px; cursor: pointer; border-bottom: 3px solid transparent; margin-bottom: -1px; color: var(--schedule-text-color); font-weight: 500; } .schedule-tab.active { color: var(--schedule-primary-color); border-bottom-color: var(--schedule-primary-color); } .schedule-panel { display: none; } .schedule-panel.active { display: block; } .schedule-table { width: 100%; border-collapse: collapse; } .schedule-table th, .schedule-table td { text-align: left; padding: 14px 20px; border-bottom: 1px solid var(--schedule-border-color); } .schedule-table th { color: #888; font-size: 0.8em; font-weight: 600; text-transform: uppercase; background-color: #F8F9FA; } .schedule-table tr:last-child td { border-bottom: none; } /* --- RULE FOR BREAKS AND PAUSES --- */ .schedule-table tr.is-break td { font-style: italic; font-size: 0.95em; color: #777; } /* --- NEW: RULE FOR 'OTHER' TYPE (More Visible) --- */ .schedule-table tr.is-other td { background-color: #f0f4ff; /* A light blue background */ font-weight: 500; /* Slightly bolder text */ } .schedule-table tr.is-other td:first-child { border-left: 4px solid var(--schedule-primary-color); } "],["meet-your-faculty.html", "Meet Your Faculty", " Meet Your Faculty Guillaume Bourque Professor, McGill University Director of Bioinformatics, Genome Quebec Innovation Centre Director, Canadian Centre of Computational Genomics Director, McGill initiative for Computational Medicine Dr. Bourque research interests are in comparative and functional genomics with a special emphasis on applications of next-generation sequencing technologies. His lab develops advanced tools and scalable computational infrastructure to enable large-scale applied research projects. Martin Hirst Distinguished Scientist, BC Cancer Professor, Department of Microbiology &amp; Immunology Director, Michael Smith Laboratories Michael Smith Laboratories Dr. Hirst’s research focuses on understanding epigenetic dysfunction in cancer and his laboratory develops experimental and computational tools to characterize normal and transformed cell types down to the single cell level. He applies these tools to explore the epigenomic states of normal and transformed cell types to discover and exploit therapeutic vulnerabilities. David Bujold Bioinformatics Manager, Data Unit Canadian Centre of Computational Genomics He joined the McGill Epigenomic Data Coordination Center at McGill in 2012 to tackle challenges related to epigenomics, and has since developed many data management and discovery solutions, including the IHEC Data Portal. Other projects of interest include CanDIG and EpiShare, platforms to make genomic and epigenomic data under controlled access more accessible, while maintaining study participants’ privacy. Jose Hector Galvez Bioinformatics Manager, Tech Dev Unit Canadian Centre of Computational Genomics As a Bioinformatics Specialist in the Research and Development team, Jose Hector is involved in maintaining, documenting, and upgrading the RNA-seq pipelines in GenPipes. He also collaborates in several research projects, mostly focusing on transcriptomics, genome assembly, and epigenomics. Edmund Su Bioinformatician Ontario Institute for Cancer Research Edmund is a bioinformatician within the genome informatics team at OICR, where he provides technical knowledge and expertise in genomic analysis. His main focus is developing pipelines and data wrangling for ICGC-ARGO (International Cancer Genome Consortium - Accelerating Research in Genomic Oncology). BF Francis Ouellette Scientific Director Canadian Bioinformatics Workshops (CBW) Montreal, QC, CA — francis@bioinformatics.ca Francis was one of the co-founders of the CBW in 1998. His teams were involved in the development of high throughput sequence analysis methods, as well as the development of platforms to integrate data from various open databases. Francis continues to be interested in computational biology and genomics, and the integration of all data types to help our understanding of biology. Rachade Hmamouchi Program Manager Canadian Bioinformatics Workshops (CBW) Montreal, QC, CA — rachade@bioinformatics.ca As a Program Manager, Rachade is leading the organization of current workshop series as well as the development of new ones. She contributes to the development and implementation of promotional strategies too. Rachade has a background in bioinformatics and project management working in academic and industrial research. She holds an MSc degree in bioinformatics and data analysis from the University of Geneva. "],["compute-setup.html", "Compute Setup", " Compute Setup Compute setup AWS Module Connecting and properly using a cloud computing cluster at the CBW here "],["module-1-introduction-to-chip-sequencing-and-analysis.html", "Module 1: Introduction to ChIP Sequencing and Analysis Lecture Lab", " Module 1: Introduction to ChIP Sequencing and Analysis Lecture Lab Common Tools of the Trade Explaination of Tools BWA Genomic Sequence Read alignment tool PICARD Toolkit for BAM file manipulation SAMTOOLS Toolkit for BAM file manipulation BEDTOOLSToolkit for BED/BEDGRAPH file manipulation MACS2 Enriched region identifier for ChIP-seq [UCSCtools])(http://genome.ucsc.edu/goldenPath/help/bigWig.html) Manipulation of Wigs and Bed/Bedgraph to binary forms Resource Files BWA INDEX: ~/CourseData/EPI_data/Module1/BWA_index/ Enhancer file.bed: ~/CourseData/EPI_data/Module1/QC_resources/ download various state7 and merge https://egg2.wustl.edu/roadmap/data/byFileType/chromhmmSegmentations/ChmmModels/coreMarks/jointModel/final/ TSS.bed: ~/CourseData/EPI_data/Module1/QC_resources/ Generated by downloading Ensemblv79 GTF convert to Bed +/-2kb of TSS. See https://www.biostars.org/p/56280/ HOX regions.bed ~/CourseData/EPI_data/Module1/QC_resources/ Generated by downloading Ensemblv79 GTF convert to Bed then selecting for HOX Hg38 Black list regions - ~/CourseData/EPI_data/Module1/QC_resources/ - https://www.encodeproject.org/files/ENCFF356LFX/@@download/ENCFF356LFX.bed.gz Resource Files CEMT Pooled Breast Basal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69069.CEEHRC.CEMT0035.H3K27ac.peak_calls.bigBed CEMT Pooled Breast Basal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69067.CEEHRC.CEMT0035.H3K27ac.signal_unstranded.bigWig CEMT Pooled Breast Basal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69063.CEEHRC.CEMT0035.H3K27me3.peak_calls.bigBed CEMT Pooled Breast Basal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69061.CEEHRC.CEMT0035.H3K27me3.signal_unstranded.bigWig CEMT Pooled Breast Basal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69054.CEEHRC.CEMT0035.H3K4me1.peak_calls.bigBed CEMT Pooled Breast Basal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69052.CEEHRC.CEMT0035.H3K4me1.signal_unstranded.bigWig CEMT Pooled Breast Basal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69057.CEEHRC.CEMT0035.H3K4me3.peak_calls.bigBed CEMT Pooled Breast Basal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69055.CEEHRC.CEMT0035.H3K4me3.signal_unstranded.bigWig CEMT Pooled Breast Basal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69070.CEEHRC.CEMT0035.Input.signal_unstranded.bigWig CEMT Pooled Breast Stromal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69088.CEEHRC.CEMT0036.H3K27ac.peak_calls.bigBed CEMT Pooled Breast Stromal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69086.CEEHRC.CEMT0036.H3K27ac.signal_unstranded.bigWig CEMT Pooled Breast Stromal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69082.CEEHRC.CEMT0036.H3K27me3.peak_calls.bigBed CEMT Pooled Breast Stromal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69080.CEEHRC.CEMT0036.H3K27me3.signal_unstranded.bigWig CEMT Pooled Breast Stromal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69073.CEEHRC.CEMT0036.H3K4me1.peak_calls.bigBed CEMT Pooled Breast Stromal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69071.CEEHRC.CEMT0036.H3K4me1.signal_unstranded.bigWig CEMT Pooled Breast Stromal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69076.CEEHRC.CEMT0036.H3K4me3.peak_calls.bigBed CEMT Pooled Breast Stromal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69074.CEEHRC.CEMT0036.H3K4me3.signal_unstranded.bigWig CEMT Pooled Breast Stromal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69089.CEEHRC.CEMT0036.Input.signal_unstranded.bigWig CEMT Pooled Breast Luminal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69107.CEEHRC.CEMT0037.H3K27ac.peak_calls.bigBed CEMT Pooled Breast Luminal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69105.CEEHRC.CEMT0037.H3K27ac.signal_unstranded.bigWig CEMT Pooled Breast Luminal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69101.CEEHRC.CEMT0037.H3K27me3.peak_calls.bigBed CEMT Pooled Breast Luminal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69099.CEEHRC.CEMT0037.H3K27me3.signal_unstranded.bigWig CEMT Pooled Breast Luminal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69092.CEEHRC.CEMT0037.H3K4me1.peak_calls.bigBed CEMT Pooled Breast Luminal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69090.CEEHRC.CEMT0037.H3K4me1.signal_unstranded.bigWig CEMT Pooled Breast Luminal ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69095.CEEHRC.CEMT0037.H3K4me3.peak_calls.bigBed CEMT Pooled Breast Luminal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69093.CEEHRC.CEMT0037.H3K4me3.signal_unstranded.bigWig CEMT Pooled Breast Luminal https://epigenomesportal.ca/tracks/CEEHRC/hg38/69108.CEEHRC.CEMT0037.Input.signal_unstranded.bigWig CEMT Pooled Breast Luminal Progenitor ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69126.CEEHRC.CEMT0038.H3K27ac.peak_calls.bigBed CEMT Pooled Breast Luminal Progenitor https://epigenomesportal.ca/tracks/CEEHRC/hg38/69124.CEEHRC.CEMT0038.H3K27ac.signal_unstranded.bigWig CEMT Pooled Breast Luminal Progenitor ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69120.CEEHRC.CEMT0038.H3K27me3.peak_calls.bigBed CEMT Pooled Breast Luminal Progenitor https://epigenomesportal.ca/tracks/CEEHRC/hg38/69118.CEEHRC.CEMT0038.H3K27me3.signal_unstranded.bigWig CEMT Pooled Breast Luminal Progenitor ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69111.CEEHRC.CEMT0038.H3K4me1.peak_calls.bigBed CEMT Pooled Breast Luminal Progenitor https://epigenomesportal.ca/tracks/CEEHRC/hg38/69109.CEEHRC.CEMT0038.H3K4me1.signal_unstranded.bigWig CEMT Pooled Breast Luminal Progenitor ~/CourseData/EPI_data/Module1/CHEERC_resources https://epigenomesportal.ca/tracks/CEEHRC/hg38/69114.CEEHRC.CEMT0038.H3K4me3.peak_calls.bigBed CEMT Pooled Breast Luminal Progenitor https://epigenomesportal.ca/tracks/CEEHRC/hg38/69112.CEEHRC.CEMT0038.H3K4me3.signal_unstranded.bigWig CEMT Pooled Breast Luminal Progenitor https://epigenomesportal.ca/tracks/CEEHRC/hg38/69127.CEEHRC.CEMT0038.Input.signal_unstranded.bigWig Module 1. BWA Alignment + BAM Post-processing Have a genome reference file ready (DONE) Index genome reference file (DONE) Run quality Check Run alignment Coordinate Sort alignment File Duplicate marking alignment Flagstats Clean up Setup mkdir ~/workspace/{alignments,fastqc} 1. Make a reference directory and download appropriate fasta reference @ https://hgdownload.cse.ucsc.edu/goldenpath/ (https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz). For the live tutorial this step was done for you. We will be using a shortened version containining only chr19 Code: mkdir ~/CourseData/BWA_index wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz -O ~/CourseData/BWA_index/ gunzip ~/CourseData/EPI_data/Module1/BWA_index/hg38.fa.gz 2 .Index Fasta using BWA. For the live tutorial, this step was done for you. Code: bwa index ~/CourseData/EPI_data/Module1/BWA_index/chr19.hg38_no_alt.fa ls ~/CourseData/EPI_data/Module1/BWA_index/ -lth Output: total 155M 8126488 -rw-rw-r-- 1 ubuntu ubuntu 28M Sep 7 19:22 chr19.hg38_no_alt.fa.sa 8126486 -rw-rw-r-- 1 ubuntu ubuntu 108 Sep 7 19:22 chr19.hg38_no_alt.fa.amb 8126485 -rw-rw-r-- 1 ubuntu ubuntu 153 Sep 7 19:22 chr19.hg38_no_alt.fa.ann 8126484 -rw-rw-r-- 1 ubuntu ubuntu 14M Sep 7 19:22 chr19.hg38_no_alt.fa.pac 8126487 -rw-rw-r-- 1 ubuntu ubuntu 56M Sep 7 19:22 chr19.hg38_no_alt.fa.bwt 8126483 -rw-rw-r-- 1 ubuntu ubuntu 57M Sep 7 18:36 chr19.hg38_no_alt.fa 3. Run Quality Check Code: mkdir -p ~/workspace/fastqc fastq_file_A=~/CourseData/EPI_data/Module1/MCF10A_resources/R1_input.fastq.gz fastq_file_B=~/CourseData/EPI_data/Module1/MCF10A_resources/R1_h3k27ac.fastq.gz fastqc ${fastq_file_A} -o ~/workspace/fastqc fastqc ${fastq_file_B} -o ~/workspace/fastqc Output: Started analysis of R1_input.fastq.gz Approx 5% complete for R1_input.fastq.gz Approx 10% complete for R1_input.fastq.gz Approx 15% complete for R1_input.fastq.gz Approx 20% complete for R1_input.fastq.gz Approx 25% complete for R1_input.fastq.gz Approx 30% complete for R1_input.fastq.gz Approx 35% complete for R1_input.fastq.gz Approx 40% complete for R1_input.fastq.gz Approx 45% complete for R1_input.fastq.gz Approx 50% complete for R1_input.fastq.gz Approx 55% complete for R1_input.fastq.gz Approx 60% complete for R1_input.fastq.gz Approx 65% complete for R1_input.fastq.gz Approx 70% complete for R1_input.fastq.gz Approx 75% complete for R1_input.fastq.gz Approx 80% complete for R1_input.fastq.gz Approx 85% complete for R1_input.fastq.gz Approx 90% complete for R1_input.fastq.gz Approx 95% complete for R1_input.fastq.gz Analysis complete for R1_input.fastq.gz Comment: Check out the HTML file produced! Note the GC distribution of Input VS H3K27ac H3K27ac 4. Run Alignment Code: mkdir -p ~/workspace/alignments ref=~/CourseData/EPI_data/Module1/BWA_index/chr19.hg38_no_alt.fa read1=~/CourseData/EPI_data/Module1/MCF10A_resources/R1_input.fastq.gz read2=~/CourseData/EPI_data/Module1/MCF10A_resources/R2_input.fastq.gz sample=MCF10A_input_chr19 bwa mem -M -t 4 ${ref} ${read1} ${read2} 2&gt;~/workspace/alignments/alignment.log | samtools view -hbS -o ~/workspace/alignments/${sample}.bam Output: Check log Code Breakdown: mkdir -p ~/workspace/alignments # Make working directory ref=~/CourseData/EPI_data/Module1/BWA_index/chr19.hg38_no_alt.fa # Preset set variables read1=~/CourseData/EPI_data/Module1/MCF10A_resources/R1_input.fastq.gz read2=~/CourseData/EPI_data/Module1/MCF10A_resources/R2_input.fastq.gz sample=MCF10A_input_chr19 bwa mem -M -t 4 ${ref} ${read1} ${read2} 2&gt;~/workspace/alignments/alignment.log # Alignment step {&quot;-t 2&quot;:Peform alignment using four threads. Our tutorial uses m5.xlarge therefore provides four cores,&quot;-M&quot;:mark short split hits as secondary} | samtools view -hbS -o ~/workspace/alignments/${sample}.bam # Converts SAM to BAM format {&quot;h&quot;:Include Header, &quot;b&quot;: output BAM, &quot;S&quot;:detect input format} 5. Coordinate Sort Alignment File Code: sample=MCF10A_input_chr19 samtools sort ~/workspace/alignments/${sample}.bam -o ~/workspace/alignments/${sample}.sorted.bam samtools view ~/workspace/alignments/${sample}.bam | head samtools view ~/workspace/alignments/${sample}.sorted.bam | head Output: Output from ~/workspace/alignments/MCF10A_input_chr19.bam: HS10_346:2:1101:3349:1883 83 chr19 49469101 60 75M = 49468882 -294 CTTGACAAGAAGGTTTTGAGGCCCCGCCCTTAGGACTCAAGTTACTAAGGAAGAGGCTGTCCTTAGCAACAGGGN DEEDDDDDDDDDDDDDDDDDDDFJJJJJJJJJJJJJJJJIIIIIIJJJJJJJJJJJJJIHJJHHHHHFFFFD=1# NM:i:1 MD:Z:74G0 MC:Z:75M AS:i:74 XS:i:0 HS10_346:2:1101:3349:1883 163 chr19 49468882 60 75M = 49469101 294 CCAGCAGGCCTGGCCAACGTGGTGACAGGAGACCGGGACCATCTGACCCGCTGCCTGGCCTTGCACCAAGACGTC CCCFFFFFGHGHGIJJJJJFHIEHIIJJJICHHIIGGIJGIJJIJJJJHGBEDDEEDDDDDDDCCDCDDDDDDBD NM:i:0 MD:Z:75 MC:Z:75M AS:i:75 XS:i:0 HS10_346:2:1101:3408:1953 83 chr19 23790237 60 75M = 23790104 -208 TCCACCCGCCTAGGCTTCCCAAAGTGGTGGGATTACAGACGTGAGCCACTGGACCCGGCCTGATTTTCTCTTGAN BDB9DDDEEFFFFFHHHHEJJJJJJJJIJJJJJJGIJJJIIJJJJJHGJJJIHJJJJJJJJJHHHHHFFFFD=1# NM:i:2 MD:Z:47G26A0 MC:Z:5M1I69M AS:i:69 XS:i:35 HS10_346:2:1101:3408:1953 163 chr19 23790104 60 5M1I69M = 23790237 208 ATTCTCCTGTCTCAGTCTCCTGAGTAGCTGGGATTACAGGCGCCCGCCACTGTGCCCGGCTACTTTTTGTATTTT CCCFFFFFDFFHHJJ?FHGIJJEHEFHIIGJJEGGIIFIIGHIJIJJJJIFIGJJIGGHEDEFEFEEED?DCFEE NM:i:1 MD:Z:74 MC:Z:75M AS:i:69 XS:i:50 HS10_346:2:1101:11940:1853 99 chr19 42651286 60 75M = 42651536 325 NTTTCTCCATCAACTTAGCTGGCAGCTCCTGTCCCCAGCAGCATCAGAGGCCCCATGAAAAGAGCTCCAGCAGGG #1=DFFFFHHHHHJJJJJJJJJIJGIJJJIIIIJJJJIJJJJJJJJJJJJJJJJJJIJIJJJJJHHHHHFFFFFD NM:i:1 MD:Z:0G74 MC:Z:75M AS:i:74 XS:i:31 HS10_346:2:1101:11940:1853 147 chr19 42651536 60 75M = 42651286 -325 GGGAGGAGAGAAGGGAACTGTAGGCCAATGGCTTTATTGGGTCTAGGGTGTTATTGACAGGTTTCCAGAAGGGAG HHHHJIJJJJJJIJIGHJJJJJJIHJJJJJIJJJJJJJJJJIGIJJJJJIHFCCCJJJJJJJHHHHHFFFFFCCC NM:i:0 MD:Z:75 MC:Z:75M AS:i:75 XS:i:0 HS10_346:2:1101:20208:1926 83 chr19 5876554 60 75M = 5876421 -208 GCGGTGAGGCCATCTATGCCCCTCGTTGGGGTCCTGGTCTTCATTGGACACCCCAGCTCCTCCCTCAGCCTGGGN DDDDDDDDDDDEDDDDDDDDFFHHHJJJJJJJJJJJJJJJJJIJJIHDD:JJJJJJJJJJJJHHHHHFFFFD=4# NM:i:2 MD:Z:15G58C0 MC:Z:32M1D24M2I17M AS:i:69 XS:i:24 HS10_346:2:1101:20208:1926 163 chr19 5876421 60 32M1D24M2I17M = 5876554 208 GGGGCTCTCTTGCCCTCCCAGCCAGATCATCCTTCTACTGGCTCCTCCAACCACCCCTGTGCCCCTGATTCTAGG CCCFFFFFHHHHHJJJJJIJJJJJJJJJJIJIIJIJJJJJIJJJICHIGHHHIIJJJCGEGGHHH=DBEFFDDEE NM:i:3 MD:Z:32^T41 MC:Z:75M AS:i:58 XS:i:0 HS10_346:2:1101:21139:1859 83 chr19 41375797 60 75M = 41375616 -256 AGCAAGACCCCGTTTTTTAAAAAATAATAATAAAAAAAAAATCCGCCGGGCGCGGTTGCTCACGCCTGTAATCCN ####################################################################?&lt;@?70# NM:i:4 MD:Z:13C29T12G17T0 MC:Z:75M AS:i:59 XS:i:28 HS10_346:2:1101:21139:1859 163 chr19 41375616 60 75M = 41375797 256 AACAAGCCAACACGCCTTCAGCACTCCTCCGCAAAAAAACACCCCTAAACAAAATAGGCCAGGCGCGGTGACTCA :+:=?;+&lt;&lt;A7=&lt;)&lt;1+1+22?@3@B&gt;B&gt;30?A04==AA#################################### NM:i:2 MD:Z:13C31A29 MC:Z:75M AS:i:65 XS:i:24 Output from ~/workspace/alignments/$MCF10A_input_chr19.sorted.bam: HS10_346:2:1304:19247:16557 117 chr19 60146 0 * = 60146 0 GTTGAGTAATTGCTGAGATGGGCAGTAGAGATGCTCAGGTCTGTGGTCCCTTTCCATCCCCACTTGATCTATTTT ########################################################################### MC:Z:54M21S AS:i:0 XS:i:0 HS10_346:2:1304:19247:16557 185 chr19 60146 60 54M21S = 60146 0 TACAAGGATAATCTGACCTGCAGGGTCGAGGAGTTGACGGTGCTGAGTTCCCTGGATGGCACCAAGATCGGCCCT DCCDDDCCCDCDECEEEFFFFHGHHIIHFGHIGGEIFAHCIEHGGIGHGHEHEDGEIIIHFG?HFFDDFFFD@@@ NM:i:0 MD:Z:54 AS:i:54 XS:i:0 HS10_346:2:1314:2495:92223 163 chr19 60167 60 75M = 60313 221 AGGGTCAAGGAGTTGACGGTGCTGAGTTCCCTGCACTCTCAGTAGGGACAGGCCCTATGCTGCCACCTGTACATG @@?DDDDDHHHHFGHJIJJFEHJJJJEIIIGHIJJJJGEIBHHGIJJIIJJJJJJJJIJJIJJJHGHHFDDFCEF NM:i:1 MD:Z:6G68 MC:Z:75M AS:i:70 XS:i:0 HS10_346:2:1207:4332:57794 99 chr19 60172 60 75M = 60350 253 CGAGGAGTTGACGGTGCTGAGTTCCCTGCACTCTCAGTAGGGACAGGCCCTATGCTGCCACCTGTACATGCTATC @C@FFDFDFFFHHIHIIJHHGGIIJGIEEHIJIJJJIJJIJJGIGHIHIHHJJJJJJJJIHHHEEHHHHFFFFFF NM:i:0 MD:Z:75 MC:Z:75M AS:i:75 XS:i:0 HS10_346:2:2315:10492:97635 121 chr19 60173 60 75M = 60173 0 GAGGAGTGGACGGTGCTGAGTTCCCTGCTCTCTCAGTAGGGACAGGCCCTATGCTGCCACCTGTACATGCTATCA ########################################################################### NM:i:3 MD:Z:7T20A45T0 AS:i:64 XS:i:0 HS10_346:2:2315:10492:97635 181 chr19 60173 0 * = 60173 0 AAAAATCGAAAATACTTTTAACAATTTGTATTTGATTTATAACTTTTAAACATTTTTATAATGACATTTAAAAAA IJIGIHFCBHEC=8GHJIIIHIEEEIHDGGHGIGIGGHGEEEGCIHHAC?HEGJJGJIIGHBHDDHHFFFFD@@@ MC:Z:75M AS:i:0 XS:i:0 HS10_346:2:1314:17241:18282 117 chr19 60211 0 * = 60211 0 CTCTGTGATCTTCTCCATGGCAGGATCTCCCAGCAGGTAAAGCAGAGCCGGAGCCAGGTGCAGGCCATTGGAGAG @CCD@@EEEHFHEA=HGGC@CF7=@@F;HF&lt;CCBBDDB9DB@&lt;&gt;GG@E@HEIHACHDDHFDADF&gt;HBDDDDB?@@ MC:Z:75M AS:i:0 XS:i:0 HS10_346:2:1314:17241:18282 185 chr19 60211 60 75M = 60211 0 GGGACAGGCCCTATGCTGCCACCTGTACATGCTATCTGAAGGACAGCCTCCAGGGCACACAGAGGATGGTATTTA ##AA=5;;BA;BB=(7.8/**)A7=909&lt;A??BB????*A:7@11)22+3&lt;3?3,33&lt;2&lt;=?CA&lt;,C7?A?===: NM:i:0 MD:Z:75 AS:i:75 XS:i:0 HS10_346:2:1201:2781:75049 99 chr19 60221 60 75M = 60484 338 CTATGCTGCCACCTGTACATGCTATCTGAAGGACAGCCTCCAGGGCACACAGAGGATGGTATTTACACATGCACA CCCFFFFFHGGHHJJIJJJJJJJJJJJJJJJJJJJIIJJJJJGIJIIJJJJJIJJJJJJ@GIIJJJJIJHHHHHF NM:i:0 MD:Z:75 MC:Z:75M AS:i:75 XS:i:0 HS10_346:2:1314:2495:92223 83 chr19 60313 60 75M = 60167 -221 CAAGCACTTCACAACCCCTCATGATCACGTGCAGCAGACAAAGTGGCCTCTGCAGAGGGGGAACGGAGACCGGAG DCADDDDEEDCDFDHIIIEJJJJIJIHFHGGIEHGIHIIJJJJJJJIJIGIJIIJJJJJJIHFGHHHFDFFFCCC NM:i:1 MD:Z:41T33 MC:Z:75M AS:i:70 XS:i:0 Code Breakdown: Coordinate sorts Comment: Take a look at the coordinate sorted bam vs original. When we view, notice the coordinates in the sorted bam were altered 6. Duplicate Marking Alignment Code: sample=MCF10A_input_chr19 java -jar /usr/local/picard/picard.jar MarkDuplicates I=~/workspace/alignments/${sample}.sorted.bam O=~/workspace/alignments/${sample}.dup_marked.sorted.bam M=~/workspace/alignments/${sample}.dup_marked.output.log ASSUME_SORTED=TRUE VALIDATION_STRINGENCY=LENIENT &gt; ~/workspace/alignments/${sample}.dup_marked.error.log Code Breakdown: java -jar \\ # Requires java to intepret /usr/local/picard/picard.jar \\ #Point to toolkit MarkDuplicates \\ #Specify function from toolkit I=~/workspace/alignments/${sample}.sorted.bam \\ #Input O=~/workspace/alignments/${sample}.dup_marked.sorted.bam \\ #output M=~/workspace/alignments/${sample}.dup_marked.output.log \\ #Work log ASSUME_SORTED=TRUE \\ #B/C we already sorted this will be true VALIDATION_STRINGENCY=LENIENT \\ #Emit warnings but keep going if possible &gt; ~/workspace/alignments/{sample}.dup_marked.error.log Output: See log. Its a bit long but the breakdown as follows: 1. A summary of the command used (so we can check the parameters) 2. A metric rollup equivalent to the flagstat step run later on 3. A histogram where, Col 1 is expected coverage col 2 is actual &quot;In case of many duplicates, the second column will result in much lower values, indicating that sequencing more will not add proportionally to the obtained effective coverage.&quot; https://github.com/broadinstitute/picard/issues/917 7. Flagstats Code: sample=MCF10A_input_chr19 samtools flagstat ~/workspace/alignments/${sample}.dup_marked.sorted.bam &gt; ~/workspace/alignments/${sample}.dup_marked.sorted.flagstat Output: 1726243 + 0 in total (QC-passed reads + QC-failed reads) 34545 + 0 secondary 0 + 0 supplementary 64636 + 0 duplicates 1545613 + 0 mapped (89.54% : N/A) 1691698 + 0 paired in sequencing 845849 + 0 read1 845849 + 0 read2 1192976 + 0 properly paired (70.52% : N/A) 1330944 + 0 with itself and mate mapped 180124 + 0 singletons (10.65% : N/A) 0 + 0 with mate mapped to a different chr 0 + 0 with mate mapped to a different chr (mapQ&gt;=5) Comment: Run flagstat on MCF10A_input_chr19.sorted.bam. What are the differences? Try running the alignment with MCF10A_H3K27ac_chr19! 8. Clean Up! Code: rm ~/workspace/alignments/${sample}.sorted.bam rm ~/workspace/alignments/${sample}.bam Comment: Good practice to remove redundant files Lab Completed! Congratulations! You have completed Lab 1! "],["module-2.html", "Module 2 Lecture Lab", " Module 2 Lecture Lab Module 2. Peak Calling Dedup BAM file Running a peak caller Remove blacklist regions Visualization Setup mkdir ~/workspace/peaks samtools index -@4 ~/CourseData/EPI_data/Module1/MCF10A_resources/*.bam 1. Dedup BAM File Code: treatment_bam=~/CourseData/EPI_data/Module1/MCF10A_resources/MCF10A_H3K27ac.bam treatment_dedup=~/workspace/peaks/MCF10A_H3K27ac.dedup.bam samtools view -@4 ${treatment_bam} -bh -q10 -F1028 -o ${treatment_dedup} input_bam=~/CourseData/EPI_data/Module1/MCF10A_resources/MCF10A_Input.bam input_dedup=~/workspace/peaks/MCF10A_Input.dedup.bam samtools view -@4 ${treatment_bam} -bh -q10 -F1028 -o ${treatment_dedup} Code Breakdown: samtools view -@4 ${treatment_bam} -bh -q10 -F1028 chr19# {&quot;-F1028&quot;: removes reads that unmapped and duplicated, &quot;-@4&quot;: uses two threads, &quot;-bh&quot;: outputs in binary, &quot;q10&quot;: MAPQ must be &gt;=10 Comments: This step will take a while, copies have been prepared in resources. Smallest file taking 3 minutes. Longest taking 10. Running a Peak Caller Code: mkdir -p ~/workspace/peaks treatment_frag=~/CourseData/EPI_data/Module1/MCF10A_resources/MCF10A_H3K27ac.dedup.bam input_frag=~/CourseData/EPI_data/Module1/MCF10A_resources/MCF10A_Input.dedup.bam name=MCF10A_H3K27ac macs3 callpeak -t ${treatment_frag} -c ${input_frag} -f BAMPE -g hs -n ${name} --keep-dup all --outdir ~/workspace/peaks/ --bdg 1&gt; ~/workspace/peaks/${name}.out.log 2&gt; ~/workspace/peaks/${name}.err.log Code Breakdown: macs3 callpeak \\ #General purpose peak calling mode -t ${treatment_frag} \\ #Treatment file, can provide more than one to &quot;pool&quot; -c ${input_frag} \\ #Control File/Input -f BAMPE \\ #Instructs MACS2 on what kind of file to expect. Single/Paired-end bed/bam -g hs \\ #Sets appropriate genome size for background sampling hs=human, mm=humouse -n ${name} \\ #name #-q 0.05 #FDR q value default #-broad #&quot;broad mode&quot; for broad marks - stitches small peaks together --outdir ~/workspace/peaks/ \\ #where to output files otherwise stores in current working directory --bdg \\ #outputs pileup into bedgraphs 1&gt; ~/workspace/peaks/${name}.out.log \\ #output log 2&gt; ~/workspace/peaks/${name}.err.log #error log cat ~/workspace/peaks/${name}.err.lo Comments: List for common marks but is not exhaustive. Best practice would be to observe trends on genome browser and then decide. Narrow Marks: H3K27ac H3K4me3 Broad Marks: H3K27me3 H3K4me1 H3K36me3 H3K36me2 H3K9me3 Take a look at the err.log we see: 1. Summary of command (a good way of troubleshooting if the wrong paramters were provided 2. Progress of loading the two bams 3. Note the line &quot;mean fragment size is determined as 227.0 bp from treatment&quot; Output: See logs 2. Black List Removal/Inspection 2.1 Black list removal Code: blacklist=~/CourseData/EPI_data/Module1/QC_resources/hg38_blacklist.bed sample=&quot;MCF10A_H3K27ac_peaks&quot; bedtools intersect -v -a ~/workspace/peaks/${sample}.narrowPeak -b ${blacklist} &gt; ~/workspace/peaks/${sample}.blacklistRemoved.narrowPeak bedtools intersect -u -a ~/workspace/peaks/${sample}.narrowPeak -b ${blacklist} &gt; ~/workspace/peaks/${sample}.blacklist.narrowPeak Output: No log. Bedtools completes Silently 2.2 NarrowPeak inspection Code: sample=&quot;MCF10A_H3K27ac_peaks&quot; wc -l ~/workspace/peaks/${sample}.blacklistRemoved.narrowPeak head ~/workspace/peaks/${sample}.blacklistRemoved.narrowPeak -n5 Output: 32384 /home/ubuntu/workspace/peaks/MCF10A_H3K27ac_peaks.blacklistRemoved.narrowPeak chr1 10003 10467 MCF10A_H3K27ac_peak_1 2160 . 47.2436 221.596 216.028 179 chr1 17283 17514 MCF10A_H3K27ac_peak_2 27 . 3.9983 5.1706 2.76136 82 chr1 180312 180997 MCF10A_H3K27ac_peak_3 803 . 28.8766 85.1306 80.3433 461 chr1 777953 778720 MCF10A_H3K27ac_peak_4 210 . 10.1154 24.4429 21.0334 503 chr1 778984 779223 MCF10A_H3K27ac_peak_5 44 . 4.87285 7.00538 4.45379 69 Comments: chromosome name peak start peak stop peak name int(-10*log10pvalue) N/A Fold change at peak summit -log10 P-value at Peak -log10 Q-value at Peak Summit position relative to peak 2.3 Quality control via % of reads in key genomic areas Code: sample=&quot;MCF10A_H3K27ac&quot; query_bam=~/CourseData/EPI_data/Module1/MCF10A_resources/${sample}.bam samtools view -@4 -q 10 -F 1028 $query_bam -c samtools view -@4 -q 10 -F 1028 $query_bam -L ~/CourseData/EPI_data/Module1/QC_resources/encode_enhancers_liftover.bed -c samtools view -@4 -q 10 -F 1028 $query_bam -L ~/workspace/peaks/${sample}_peaks.blacklistRemoved.narrowPeak -c Output: 19632094 10752392 2028377 Comments: samtools view #Viewing entirety or subset of BAM file -q 10 \\ #Parsing for reads with 5&gt;=MAPQ -F 1028 \\ # Remove reads that have the following flags:UNMAP,DUP #https://broadinstitute.github.io/picard/explain-flags.html $query_bam \\ # Bam of interest -c # Count number of reads instead of displaying -L # Region of interest. Bed File Enrichment at key regions: H3K4me1 H3K27me3 H3K27ac H3K4me3 Reads Count Total 71,545,746 55,438,916 19,632,094 26,381,511 Enhancer 48,466,245 25,742,977 10,752,392 12,302,265 HOX 13,866 13,085 4,504 28,674 TSS 7,303,584 5,111,631 2,702,194 18,041,080 In Peaks 27,539,876 25,072,097 2,028,377 20,920,281 H3K4me1 H3K27me3 H3K27ac H3K4me3 Percent of Total Total 100.00 100.00 100.00 100.00 Enhancer 67.74 46.43 54.77 46.63 HOX 0.02 0.02 0.02 0.11 TSS 10.21 9.22 13.76 68.39 In Peaks 38.49 45.22 10.33 79.30 Lab Completed! Congratulations! You have completed Lab 2! "],["module-3.html", "Module 3 Lecture Lab", " Module 3 Lecture Lab 3. Visualization 3.1 Visualization (Coverage) Code: mkdir -p ~/workspace/{bigBed,bigWig} sample=&quot;MCF10A_H3K27ac&quot; input_bedgraph=~/workspace/peaks/${sample}_treat_pileup.bdg output_bigwig=~/workspace/bigWig/${sample}_treat_pileup.bw chrom_sizes=~/CourseData/EPI_data/Module1/QC_resources/hg38.chrom.sizes sort -k1,1 -k2,2n ${input_bedgraph} &gt; ~/workspace/bigWig/tmp bedGraphToBigWig ~/workspace/bigWig/tmp ${chrom_sizes} ${output_bigwig} rm ~/workspace/bigWig/tmp input_bedgraph=~/workspace/peaks/${sample}_control_lambda.bdg output_bigwig=~/workspace/bigWig/${sample}_control_lambda.bw chrom_sizes=~/CourseData/EPI_data/Module1/QC_resources/hg38.chrom.sizes sort -k1,1 -k2,2n ${input_bedgraph} &gt; ~/workspace/bigWig/tmp bedGraphToBigWig ~/workspace/bigWig/tmp ${chrom_sizes} ${output_bigwig} rm ~/workspace/bigWig/tmp Output: N/A Code Breakdown: mkdir -p ~/workspace/{bigBed,bigWig} sample=&quot;MCF10A_H3K27ac&quot; # Specify variables input_bedgraph=~/workspace/peaks/${sample}_treat_pileup.bdg # output_bigwig=~/workspace/bigWig/${sample}_treat_pileup.bw # chrom_sizes=~/CourseData/EPI_data/Module1/QC_resources/hg38.chrom.sizes # sort -k1,1 -k2,2n ${input_bedgraph} &gt; ~/workspace/bigWig/tmp # Sorts peaks as to match alphabetical order in col 1 and numerical in col 2 #$(chrom_sizes) into a temporary file bedGraphToBigWig ~/workspace/bigWig/tmp ${chrom_sizes} ${output_bigwig} # Conversion step rm ~/workspace/bigWig/tmp #remove temporary file 3.2 Visualization (Peaks) Code: mkdir -p ~/workspace/{bigBed,bigWig} sample=&quot;MCF10A_H3K27ac&quot; input_bed=~/workspace/peaks/${sample}_peaks.blacklistRemoved.narrowPeak output_bigbed=~/workspace/bigBed/${sample}_peaks.blacklistRemoved.bb chrom_sizes=~/CourseData/EPI_data/Module1/QC_resources/hg38.chrom.sizes cut -f1-3 ${input_bed} | sort -k1,1 -k2,2n &gt; ~/workspace/bigBed/tmp bedToBigBed ~/workspace/bigBed/tmp ${chrom_sizes} ${output_bigbed} rm ~/workspace/bigBed/tmp Output: N/A Code Breakdown: sample=&quot;MCF10A_H3K27ac&quot; input_bed=~/workspace/peaks/${sample}_peaks.blacklistRemoved.narrowPeak output_bigbed=~/workspace/bigBed/${sample}_peaks.blacklistRemoved.bb chrom_sizes=~/CourseData/EPI_data/Module1/QC_resources/hg38.chrom.sizes cut -f1-3 ${input_bed} | sort -k1,1 -k2,2n &gt; ~/workspace/bigBed/tmp bedToBigBed ~/workspace/bigBed/tmp ${chrom_sizes} ${output_bigbed} # Largely the same as above, except we trim our narrowPeak file to just 3 columns rm ~/workspace/bigBed/tmp 3.3 Visualization Download tracks via public url Upload onto IGV Explore! Comments: If you’re following via amazon AWS, you should have a public port open to the IPv4 associated with your instance in which you can interact via browser The files you would want to import would be: /BigBed//MCF10A_H3K27ac_peaks.blacklistRemoved.bb //bigWig/bigWig/${sample}_treat_pileup.bw /bigWig/${sample}_control_lambda.bw Lab Completed! Congratulations! You have completed Lab 3! "],["module-4.html", "Module 4 Lecture Lab", " Module 4 Lecture Lab 1. Introduction Description of the lab: This module will cover the basics of Whole Genome Bisulfite-Sequencing (WGBS) data analysis including data visualization in IGV. Objectives: Learn how to align WGBS data using Bismark 2) Learn how to generate a methylation profile with Bismark 3) Learn how to open alignments and methylation profiles in the IGV genome browser 4) Learn how to perform a basic differential methylation analysis with MethylKit Local software that we will use: Before you begin, make sure you have the following programs ready in your local computer: A connection to the EPI_2021 AWS instance An internet browser IGV R (or RStudio), optional 2. Mapping Tutorial 2.1 Getting Started Prepare Directory for the Lab mkdir -p ~/workspace/module4 cd ~/workspace/module4 Save Genome Location GENOME=~/CourseData/EPI_data/module4/Homo_sapiens.GRCh38.chr19 export GENOME This will define a variable $GENOME that will simplify future commands. Locate the Data for the Workshop WGBS_DATA=~/CourseData/EPI_data/module4/data export WGBS_DATA This will define a variable $WGBS_DATA that will simplify future commands. Check the Files Question 1 Type the following command: ls $WGBS_DATA, what do you see? Answer You should see something similar to this: WGBS.A34002.137160.chr19.1.fastq.gz WGBS.A34002.137160.chr19.2.fastq.gz WGBS.A34002.137487.chr19.1.fastq.gz WGBS.A34002.137487.chr19.2.fastq.gz WGBS.A34002.137488.chr19.1.fastq.gz WGBS.A34002.137488.chr19.2.fastq.gz These are the files that will be used for the workshop. They contain a subset of WGBS reads from CEMT sample CEMT0007, which is a mammary gland epithelial cell line (more information here). Question 2 What do the “.1” and “.2” in the file names mean? Answer They represent the read1 and read2 of the paired end reads. 2.2 Map Data using Bismark We will now process and map the reads using the Bismark WGBS aligner (more info here). Map the first dataset using Bismark To simplify the work, we will process the datasets one at a time. To align the first dataset, do the following: cd ~/workspace/module4 bismark --multicore 4 --bowtie2 $GENOME/genome/bismark_index \\ -1 $WGBS_DATA/WGBS.A34002.137160.chr19.1.fastq.gz -2 $WGBS_DATA/WGBS.A34002.137160.chr19.2.fastq.gz Question 3 What do all the options in the command mean? (Hint check the help by using bismark --help) Answer The --multicore 4 option is to do multithreaded processing to improve speed The --bowtie2 option is to use the mapping algorithm from bowtie2 The $GENOME/genome/bismark_index specifies the location of the index for the reference genome to use. This uses the $GENOME variable we defined previously The -1 $WGBS_DATA/WGBS.A34002.137160.chr19.1.fastq.gz specifies the location of read 1. Idem for -2 which specifies read 2. This uses the $WGBS_DATA variable we defined previously. For more details, please refer to the Bismark user guide. This step will take a few minutes to run for this reduced dataset. A dataset spanning a full genome will take several hours. For your own datasets, make sure you have enough computing walltime to run the alignment. While you wait for the results, ask any questions you have up to this point to the instructors. Check files At the end of the alignment, you should have the following files saved into your workshop folder: WGBS.A34002.137160.chr19.1_bismark_bt2_pe.bam WGBS.A34002.137160.chr19.1_bismark_bt2_PE_report.txt Let’s look at the report: less WGBS.A34002.137160.chr19.1_bismark_bt2_PE_report.txt Question 4 What was the mapping efficiency? What percent of C’s were methylated in CpG context? Answer According to the report: ... Mapping efficiency: 92.4% ... C methylated in CpG context: 57.4% C methylated in CHG context: 0.6% C methylated in CHH context: 0.5% C methylated in unknown context (CN or CHN): 3.5% ... Close the report by pressing q. Prepare files for loading in IGV We need to sort the bam file and prepare an index so we will be able to load it in IGV. We will use the program samtools for this. samtools sort WGBS.A34002.137160.chr19.1_bismark_bt2_pe.bam -o WGBS.A34002.137160.chr19.1_bismark_bt2_pe_sorted.bam samtools index WGBS.A34002.137160.chr19.1_bismark_bt2_pe_sorted.bam Check Files At the end, you should have the following files: WGBS.A34002.137160.chr19.1_bismark_bt2_pe_sorted.bam WGBS.A34002.137160.chr19.1_bismark_bt2_pe.bam WGBS.A34002.137160.chr19.1_bismark_bt2_pe_sorted.bam.bai WGBS.A34002.137160.chr19.1_bismark_bt2_PE_report.txt 2.3 Repeat Alignment for All Datasets Question 5 How would you repeat the alignment with the other datasets? Answer This is the command to run bismark on the two other samples: cd ~/workspace/module4 bismark --multicore 4 --bowtie2 $GENOME/genome/bismark_index \\ -1 $WGBS_DATA/WGBS.A34002.137487.chr19.1.fastq.gz -2 $WGBS_DATA/WGBS.A34002.137487.chr19.2.fastq.gz bismark --multicore 4 --bowtie2 $GENOME/genome/bismark_index \\ -1 $WGBS_DATA/WGBS.A34002.137488.chr19.1.fastq.gz -2 $WGBS_DATA/WGBS.A34002.137488.chr19.2.fastq.gz Remember, for the command to work, both $GENOME and $WGBS_DATA need to be defined. This is the command to prepare the samples for IGV (sort and index): samtools sort WGBS.A34002.137487.chr19.1_bismark_bt2_pe.bam -o WGBS.A34002.137487.chr19.1_bismark_bt2_pe_sorted.bam samtools index WGBS.A34002.137487.chr19.1_bismark_bt2_pe_sorted.bam samtools sort WGBS.A34002.137488.chr19.1_bismark_bt2_pe.bam -o WGBS.A34002.137488.chr19.1_bismark_bt2_pe_sorted.bam samtools index WGBS.A34002.137488.chr19.1_bismark_bt2_pe_sorted.bam 2.4 Load Data and Explore using IGV While you wait for the previous steps to finish executing, it is a good idea to begin exploring the alignments. Copy Files to Your Local Computer to View in IGV (optional) Retrieve the files called WGBS.A34002.137160.chr19.1_bismark_bt2_pe_sorted.bam and WGBS.A34002.137160.chr19.1_bismark_bt2_pe_sorted.bam.bai from the server using your internet browser and the public IP address of your AWS instance. Launch IGV on your computer If you haven’t installed it yet, please get it here IGV download. Make sure that the human genome is selected in the top left corner. It should read: Human (hg38). Load your sorted bam file in IGV using File -&gt; Load from file. For this to work, you need to have the index file (.bai) in the same location as the bam file. You can also load this directly from the internet using the URL of this file you got from your public IP page, using File -&gt; Load from URL. Now, on IGV, go to the following location: chr19:43,375,889-45,912,052 And zoom in until you see something. For instance, try the following window: chr19:44,527,387-44,536,873 You should see something like this: If it looks different, can you change the way the colors are displayed? Which section of which chromosome is covered by this dataset? Can you see any interesting patterns in the coverage? 2.5 Generate Methylation Profiles So far we have only mapped the reads using Bismark. We can generate methylation profiles using the following command: cd ~/workspace/module4 bismark_methylation_extractor --bedGraph WGBS.A34002.137160.chr19.1_bismark_bt2_pe.bam Question 6 How would you do the same for the other replicates? Answer These are the commands that you should use: cd ~/workspace/module4 bismark_methylation_extractor --bedGraph WGBS.A34002.137487.chr19.1_bismark_bt2_pe.bam bismark_methylation_extractor --bedGraph WGBS.A34002.137488.chr19.1_bismark_bt2_pe.bam Make sure that all the files produced so far are displayed in your internet browser. While you wait for all the steps to finish, you can ask the instructors any questions you might have up until this point. Load all the files in IGV using File -&gt; Load from file or File -&gt; Load from URL. At this point, if you load the region chr19:44,527,387-44,536,873 you should see something like This promoter looks to be hypomethylated. Can you find a promoter that is hypermethylated? How about chr19:45,637,715-45,657,380? How would you look for a CpG island using this view of the data? Keep exploring the files and see if you can find differences in the methylation profiles of the samples. 3. Differential Methylation Analysis in MethylKit The following section will use the Bioconductor package methylKit to do a differential methylation analysis. You can do it in your own computer (if you have installed R and methylKit) or in the AWS instance. To install methylKit locally on your computer, make sure you have a recent version of R and follow the instructions in this page. 3.1 Load R and MethylKit If you are working in AWS, you will need to load R. The image we provide already has the libraries we need. To launch R simply type the following to your terminal: cd ~/workspace/module4 R If you did this properly, the following message will be displayed and your prompt will change from ubuntu@ip-00-00-00-0:~/workspace/module4$ to &gt;: R version 4.0.5 (2021-03-31) -- &quot;Shake and Throw&quot; Copyright (C) 2021 The R Foundation for Statistical Computing Platform: x86_64-pc-linux-gnu (64-bit) ... Once you have successfully launched R, you can load methylKit with the following command: library(&quot;methylKit&quot;) 3.2 Import the Alignment Data into MethylKit Process Bismark Alignments To read the alignment data into methylKit, run the following command: methRaw.160 = processBismarkAln( location = &quot;WGBS.A34002.137160.chr19.1_bismark_bt2_pe_sorted.bam&quot;, sample.id=&quot;A34002.137160&quot;, assembly=&quot;hg38&quot;, read.context=&quot;CpG&quot;, save.folder=&quot;methylkit&quot;) This command will import the data into a format that is readable by methylKit. At the same time, it will save two files under the methylkit directory with the information so that it is easy to load again at any time: methylkit/A34002.137160_CpG_conversionStats.txt methylkit/A34002.137160_CpG.txt If everything goes well and you see the files, do the same for the other two samples: methRaw.487 = processBismarkAln( location = &quot;WGBS.A34002.137487.chr19.1_bismark_bt2_pe_sorted.bam&quot;, sample.id=&quot;A34002.137487&quot;, assembly=&quot;hg38&quot;, read.context=&quot;CpG&quot;, save.folder=&quot;methylkit&quot;) methRaw.488 = processBismarkAln( location = &quot;WGBS.A34002.137488.chr19.1_bismark_bt2_pe_sorted.bam&quot;, sample.id=&quot;A34002.137488&quot;, assembly=&quot;hg38&quot;, read.context=&quot;CpG&quot;, save.folder=&quot;methylkit&quot;) Create a MethylKit Object Now that all the samples have been read with methylKit, you can create a file list to make it easier to load the full dataset as a methylkit object. For the purposes of this tutorial, we will consider that samples belong to two experimental groups: A34002.137160 as the control group (treatment = 0) and A34002.137487 &amp; A34002.137488 as the treatment group (treatment = 1). We use the methRead() function to create our object, as shown below: file.list = list( file.path(&quot;methylkit&quot;, &quot;A34002.137160_CpG.txt&quot;), file.path(&quot;methylkit&quot;, &quot;A34002.137487_CpG.txt&quot;), file.path(&quot;methylkit&quot;, &quot;A34002.137488_CpG.txt&quot;) ) myobj = methRead(file.list, sample.id=list(&quot;A34002.137160&quot;,&quot;A34002.137487&quot;,&quot;A34002.137488&quot;), assembly=&quot;hg38&quot;, treatment=c(0,1,1), context=&quot;CpG&quot;, mincov = 10 ) Question 7 What do all the options in the methRead() command mean? Answer file.list object points to the location of the input data in a MethylKit format. sample.id points to a list with the appropriate sample name for each file. assembly specifies which build of the human reference genome is used. treatment specifies which sample belongs to each experimental group. context specifies the methylation context. mincov specifies the minimum coverage required to be included in the object. For more details, please refer to the MethylKit user guide. If the files were loaded properly, you can check the object you just created by running the following command: myobj Which should output the following message followed by previews of the contents of the object: methylRawList object with 3 methylRaw objects ... You can also get basic statistics on your object by using the following command: getMethylationStats(myobj[[2]],plot=FALSE,both.strands=FALSE) 3.3 Find Differentially Methylated Regions Merge Samples Before doing any additional analysis, methylKit needs to determine which methylated bases have sufficient coverage in all samples so they can be compared. To do that, the samples should be merged with the unite() function. This function has a parameter destrand= that is turned off by default. We will set the destrand option to TRUE which will merge the coverage of both strands. When doing your own analyses, be aware that for some kinds of methylation analyses (such as CpH methylation) results are strand-specific, so this option should be used carefully. meth = unite(myobj, destrand=TRUE) Perform Differential Methylation Analysis The standard function for Differential Methylation Analysis on methylKit is calculateDiffMeth(). It takes any merged methylkit object as input. Depending on the number of replicates, it uses either Fisher’s exact or logistic regression to calculate P-values. It also, automatically produces Q-values, which are a kind of adjusted P-value. To use it with the results we obtained before, run the following command: myDiff = calculateDiffMeth(meth) To check the output, just type myDiff and read the summary. If you want an example of the output, check the solution below. Example This is what the output looks like: methylDiff object with 2941 rows -------------- chr start end strand pvalue qvalue meth.diff 1 chr19 42002896 42002896 + 3.271268e-01 0.69569299 8.951407 2 chr19 42002978 42002978 + 1.912989e-01 0.60732656 -21.666667 3 chr19 42007251 42007251 + 6.999764e-05 0.03228847 -55.681818 4 chr19 42007255 42007255 + 3.958578e-01 0.75196047 -11.835106 5 chr19 42007283 42007283 + 8.451850e-01 0.91347038 -2.457757 6 chr19 42007314 42007314 + 9.102723e-01 0.92865750 -1.604278 -------------- sample.ids: A34002.137160 A34002.137487 A34002.137488 destranded TRUE assembly: hg38 context: CpG treament: 0 1 1 resolution: base To filter results by their statistical significance, methylKit provides the getMethylDiff() function which allows you to extract only the deferentially methylated CpG’s that meet a specific Q-value threshold. Additionally, it is also possible to specify whether to keep hypo or hyper methylated CpG’s only. Finally, the bedgraph() function allows you to save the the methylDiff object into a BedGraph file so you can open it with your genome browser of choice. Let’s create two BedGraph files with hypo and hyper methylated CpG’s with a Q-value below 0.05 based on the data above: myDiff.hyper = getMethylDiff(myDiff,qvalue=0.05,difference=10,type=&quot;hyper&quot;) bedgraph(myDiff.hyper, file.name = &quot;hyper.CpG.bedGraph&quot;, col.name = &quot;qvalue&quot;) myDiff.hypo = getMethylDiff(myDiff,qvalue=0.05,difference=10,type=&quot;hypo&quot;) bedgraph(myDiff.hypo, file.name = &quot;hypo.CpG.bedGraph&quot;, col.name = &quot;qvalue&quot;) Two new files should appear now in your workshop folder: ~/workspace/module4/hyper.CpG.bedGraph ~/workspace/module4/hypo.CpG.bedGraph Bin Results to Obtain Differentially Methylated Regions By default, methylKit will compute results with an individual CpG resolution. To get Differentially Methylated Regions (DMR), you have to bin your results first, using a window size of your choice. The function to do this is tileMethylCounts(), which takes a regular methylkit object as input. In this case, we will create 1000bp bins using the following command: tiles = tileMethylCounts(myobj,win.size=1000,step.size=1000,cov.bases = 10) As with CpG level results, samples need to be merged before the analysis can continue: meth.tiles = unite(tiles, destrand=TRUE) Now, we will use the calculateDiffMeth() and getMethylDiff() functions to get the DMRs. Questions 8 &amp; 9 Do you know how to do it, based on the information above? Based on the number of differentially methylated CpGs you found above, do you anticipate many statistically significant DMRs in your analysis? Answer Use the following commands to perform a DMR analysis: myDiff.tiles = calculateDiffMeth(meth.tiles) myDiff.tiles.hyper = getMethylDiff(myDiff.tiles,qvalue=0.1,difference=10,type=&quot;hyper&quot;) bedgraph(myDiff.tiles.hyper, file.name = &quot;hyper.DMR.bedGraph&quot;, col.name = &quot;qvalue&quot;) myDiff.tiles.hypo = getMethylDiff(myDiff.tiles,qvalue=0.1,difference=10,type=&quot;hypo&quot;) bedgraph(myDiff.tiles.hypo, file.name = &quot;hypo.DMR.bedGraph&quot;, col.name = &quot;qvalue&quot;) Using the navigation pane, download the bedGraph files you just produced and try to open them with IGV. Do the statistical results match what you had seen before when exploring the data? What interesting genomic features are found close to the DMRs? What could this mean? Congrats, you’re done! You can quit R using the quit() or q() command. Remember to stop your AWS instance after this lab to avoid unnecessary costs. Once you are finished make sure you download all the files you need and continue exploring on IGV. Lab Completed! Congratulations! You have completed Lab 4! "],["module-5-downstream-analyses-integrative-tools.html", "Module 5: Downstream Analyses &amp; Integrative Tools Lecture Lab", " Module 5: Downstream Analyses &amp; Integrative Tools Lecture Lab Introduction Description of the lab We will now explore some of the tools that were covered in the lecture for module 5. In Lab Part 1, we will: Learn how to use the IHEC Data Portal’s tools to fetch feature tracks of interest. Explore ChIP-Seq peak prediction files (in bed format) to discover motifs using HOMER. Use an IHEC dataset with the GREAT GO enrichment tool to do functions prediction. In Lab Part 2, we will explore the Galaxy web platform and launch a few jobs on it. Local Software That will be Needed Tool to connect to your remote terminal session (e.g. Putty in Windows) A web browser The IGV genome browser Lab Part 1 Preparation in your AWS session From your command line terminal, go to your workspace folder. cd ~/workspace You will be in your home folder. Prepare directory for module 5 If it exists, remove any module5 directory in your home directory with the “rm” command. Create a new module5 directory. Go to that directory. rm -rf module5 mkdir module5 cd module5 IHEC Data Portal Exploring Available Datasets Open a web browser on your computer, and load the URL http://epigenomesportal.ca/ihec In the Overview page, click on the “View all” button, below the pie charts You will get a grid with all available datasets for IHEC Core Assays, on the hg38 assembly You can filter out visible datasets in the grid using the filtering options at the right of the grid Go back to the Overview page (Home on the top menu), and select the following categories of datasets: On the “hg38” reference genome, “Histone” experiments for the “Blood” cell type. Click on View selected Only these categories will now get displayed in the grid. Expand the “Blood” category by clicking on the black triangle, and select the following grid cell: Visualizing the Tracks Click on the “Send” button for the UCSC Genome Browser, at the bottom of the grid You can see that the datasets are being displayed on the UCSC Genome Browser. These are all peaks and signal for the chosen blood H3K27ac ChIP-Seq datasets. In the Genome Browser, you can expand the tracks by changing visibility from “pack” to “full” and clicking the “Refresh” button You can also download these tracks locally for visualization in IGV Go back to the IHEC Data Portal tab Click on the “Download tracks” button at the bottom of the grid Use the download links to download a few of the available tracks Open them in IGV Tracks Correlation You can get a whole genome overview of the similarity of a group of tracks by using the Portal’s correlation tool. Back on the Data Grid tab of your browser, from the filters at the right of the grid, add back datasets for all tissues and all assay types. You can select all checkboxes at once by click on the top checkbox, next to “Category”. Also remove non-core assays if it is selected Select all ChIP-Seq marks for the cell type “Myeloid cell”, under the “Bone Marrow” category. The first 6 columns should be selected At the bottom of the grid, click on the button “Correlate datasets” You will see that similar tracks (e.g. those of the same assay, seem to correlate nicely. You can zoom in the view with the mouse scrolling wheel, or with the buttons at the lower right corner of the popup You can also use the correlation tool to assess whether datasets that are supposed to be similar actually are Close the correlation popup window with the top right “X” button Reset grid selection with the “Reset” button at the bottom of the grid Click on the grid cell for cell type “CD4-positive, alpha-beta T cell”, under the “Blood” category, and assay “H3K27ac” Click on “Correlate datasets” One dataset seems to be an outlier. This could be, for instance, a problem with the quality of the dataset, or the underlying metadata can indicate that something is different (disease status or some other key element) You should get something like this: Predicting Motifs with HOMER We will now attempt to detect motifs in peak regions for transcription factor binding sites using HOMER Reset to the default IHEC Data Portal view by clicking “Data Grid” in the top bar Choose Assembly hg19. In the filters to the right of the grid, activate non-core IHEC assays, and display only Transcription Factor Binding Sites (TFBS) assays In the grid, select ENCODE datasets for the CTCF assay and the B cell cell type Go to the track list at the bottom of the grid and select only the dataset for sample “ENCBS400ARI” You can get the URL to the track you want by clicking on the “Download tracks” button at the bottom of the grid Here, we’re interested in https://epigenomesportal.ca/tracks/ENCODE/hg19/84840.ENCODE.ENCBS400ARI.CTCF.peak_calls.bigBed. This file contains peaks that were called out of the TFBS ChIP-Seq experiment Useful tip: You can get the full set of metadata about ENCODE experiments and samples by consulting the ENCODE portal, and searching for a given sample name. In this case: https://www.encodeproject.org/biosamples/ENCBS400ARI/ Open your AWS terminal session, create a directory for our HOMER-related files, and go into it. Then, download the BigBed file mkdir homer cd homer wget https://epigenomesportal.ca/tracks/ENCODE/hg19/84840.ENCODE.ENCBS400ARI.CTCF.peak_calls.bigBed UCSC provides a set of file format conversion tools, such as bigBedToBed, which converts a binary bigbed file to its plain text file equivalent. Some of these tools have been pre-installed on your AWS image Convert the bigBed file into a bed file using the UCSC set of tools bigBedToBed 84840.ENCODE.ENCBS400ARI.CTCF.peak_calls.bigBed 84840.ENCODE.ENCBS400ARI.CTCF.peak_calls.bed Prepare an output directory for HOMER, and a genome preparsed motifs directory mkdir output mkdir preparsed Run the HOMER software to identify motifs in the peak regions -p 4 indicates to use 4 cores. -S 15 tells Homer to find 15 motifs, instead of the default 25, for execution speed purposes. You can get the full list of parameters here: http://homer.ucsd.edu/homer/ngs/peakMotifs.html findMotifsGenome.pl 84840.ENCODE.ENCBS400ARI.CTCF.peak_calls.bed hg19 output -preparsedDir preparsed -p 4 -S 15 HOMER takes a while to execute for a whole genome track like this. Expect this job to take about 30 minutes of runtime, with your current setup. In the meantime, we will explore the GO terms enrichment tool GREAT Looking for GO Terms Enrichment with GREAT Next, we will try to identify GO terms connected to ChIP-Seq peaks calls using GREAT. We need bed files to use the GREAT portal. We will do the conversion from a bigBed file to a bed file on our AWS session In the IHEC Data Portal, go back to the default grid page (by clicking on Data Grid in the top bar). For assembly Human (hg38), filter the tissues list to keep only “Bone Marrow” tissues Select the datasets for cell type “Myeloid cell” and assay H3K27ac For this exercise, we will download only one of the bigbeds for available datasets. Pick up the dataset below, for sample ERS1027405: Click “Download tracks” at the bottom of the grid On the download page, click on View Full URL List. This will give you a text list with all tracks of interest Copy the link to this page in your clipboard, using the address provided in your browser’s URL bar Open another terminal session to get into AWS Go to your module5 directory and create a place to put the material we will download cd ~/workspace/module5 mkdir great cd great For you own analyses, you can download a bunch of tracks at the same time by using wget on a list of URLs Use the wget command to download the text file that contains the list of tracks wget -O trackList.txt &#39;https://epigenomesportal.ca/api/datahub/download?session=18731&amp;format=text&#39; Now download the tracks that are contained in this list wget -i trackList.txt Convert the bigbed using the UCSC set of tools bigBedToBed 58394.Blueprint.ERS1027405.H3K27ac.peak_calls.bigBed 58394.Blueprint.ERS1027405.H3K27ac.peak_calls.bed Note If you’re under Linux / Mac, you can also install the UCSC tools locally, as they are a useful set of tools to manipulate tracks data, without requiring so much processing power. GREAT has a limit on the number of regions to be tested in one execution. Therefore, we need to subsample our file. We can create a BED file subsample this way: Sort BED file in random order with sort -R Take the 20000 first lines in the file with head -n20000 sort -R 58394.Blueprint.ERS1027405.H3K27ac.peak_calls.bed &gt; 58394.Blueprint.ERS1027405.H3K27ac.peak_calls.random.bed head -n 20000 58394.Blueprint.ERS1027405.H3K27ac.peak_calls.random.bed &gt; 58394.Blueprint.ERS1027405.H3K27ac.peak_calls.random_short.bed From your local computer, download the BED file 58394.Blueprint.ERS1027405.H3K27ac.peak_calls.random_short.bed locally using your browser http://&lt;your VM ip address&gt;/module5/great/58394.Blueprint.ERS1027405.H3K27ac.peak_calls.random_short.bed Load the GREAT website: http://bejerano.stanford.edu/great/public/html/ Provide the following input to the GREAT interface: Assembly: Human: GRCh38 Test regions: The randomized short version of the BED files you just downloaded (58394.Blueprint.ERS1027405.H3K27ac.peak_calls.random_short.bed) Leave the “Background regions” to its default value, “Whole Genome” Submit the form In the results, for instance, you should obtain something like this for biological processes: Bonus question: Why is your result slightly different from the screenshot? Going back to HOMER Results Is the job done? If it is completed, you can bring back HOMER results to your laptop for visualization. First we’ll compress the results to a zip file cd ~/workspace/module5/homer/ zip -r homer.zip output Next, with your web browser, download the zipped result set http://&lt;your VM ip address&gt;/module5/homer/homer.zip Unzip the file, and open the de novo and known motifs HTML files in a browser for visualization. Do the identified motifs fit what we would expect? All done! If you have time remaining, you can explore further the tools that we covered in this lab, using other types of datasets. For example, does running a GREAT query on another cell type yield the type of annotations that you’d expect? Interested in exploring Galaxy? You can start tackling a Galaxy introduction extra lab, available here. It uses the usegalaxy.org server, so you can also follow it at your own pace after the workshop. Lab Completed! Congratulations! You have completed Lab 5! "]]
